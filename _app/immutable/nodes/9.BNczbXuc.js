import"../chunks/CWj6FrbW.js";import"../chunks/69_IOA4Y.js";import{f as n,a as e,b as a,s as o,n as t,t as R}from"../chunks/BWp35gWV.js";import{T as F}from"../chunks/CR7k0xtG.js";import{P as p}from"../chunks/B7flgP-x.js";import{M as r}from"../chunks/BqyEoRxA.js";import{P as b}from"../chunks/DPzc5wQr.js";/* empty css                *//* empty css                *//* empty css                *//* empty css                *//* empty css                *//* empty css                *//* empty css                */import{S as G}from"../chunks/LIUKG8Hf.js";var H=n(`Есть датасет, состоящий из <!> записей.
    Каждая <!>-я запись имеет <!> факторов <!> и одно значение целевой переменной <!>.`,1),I=n("Нужно составить такую линейную функцию <!>",1),J=n("<!> <!>",1),K=n(`Давайте для начала соберём все наши регрессоры (наблюдения и значения факторов для каждого наблюдения)
    в одну матрицу <!>, добавив к ней единичный столбец для учёта свободного члена.`,1),L=n("<!> <!> <!> <!>",1),N=n(`Задача линейной регрессии свелась к нахождению вектора коэффициентов <!>,
    который обеспечивает минимальность остатка <!>`,1),O=n("<!> <!>",1),Q=n(`Давайте решим эту задачу.
    Минимальность остатка <!> мы будем мерить
    с помощью функции потерь RSS &mdash; сумма квадратов остатков`,1),U=n("Остаток у нас выражается через уравнение регрессии <!>",1),V=n("Чтобы найти минимум функции <!>, найдём градиент по <!> и приравняем его к <!>",1),W=n("Раскроем скобки и приведём подобные слагаемые в выражении для <!>",1),Y=n(`Тогда <!>.
    Мы получили систему уравнений <!>.
    Решением этой системы является`,1),Z=n(`Чтобы убедиться в том, что это действительно минимум функции потерь, нам надо вычислить гессиан функции потерь.
    У нас <!>.
    Матрица <!> положительно полуопределена, ведь для любого вектора <!> имеет
    место неравенство <!>.
    А значит и гессиан положительно полуопределён, то есть найденная точка действительно минимум.`,1),oo=n("<!> <!> <!> <!> <!> <!> <!> <!> <!> <!> <!> <!>",1),ro=n("Тогда матрица <!> с точностью до константы становится ковариационной матрицей факторов",1),to=n(`А вектор <!> с точностью до константы становится
    вектором ковариаций целевой переменной с факторами`,1),ao=n("<!> <!> <!> <!> <!>",1),_o=n("<!> <!> <!> <!> <!> <!>",1);function go(B){var j=_o(),M=e(j);F(M,{title:"Линейная регрессия"});var k=o(M,2);G(k,{title:"Задача линейной регрессии",children:(f,P)=>{var m=J(),i=e(m);p(i,{children:(l,X)=>{t();var v=H(),d=o(e(v));r(d,{m:"n"});var s=o(d,2);r(s,{m:"j"});var c=o(s,2);r(c,{m:"p"});var T=o(c,2);r(T,{m:"x_{j, \\- 1}, x_{j, \\- 2}, \\dotsc, x_{j, \\- p}"});var S=o(T,2);r(S,{m:"y_j"}),t(),a(l,v)}});var y=o(i,2);p(y,{children:(l,X)=>{t();var v=I(),d=o(e(v));r(d,{m:"y = a^\\T \\cdot x + b + \\epsilon"}),a(l,v)}}),a(f,m)}});var q=o(k,2);b(q,{children:(f,P)=>{var m=L(),i=e(m);p(i,{children:(v,d)=>{t();var s=K(),c=o(e(s));r(c,{m:"X"}),t(),a(v,s)}});var y=o(i,2);r(y,{display:!0,m:`X = \\pmatrix{
          1 & x_{1, \\- 1} & x_{1, \\- 2} & x_{1, \\- 3} & \\cdots & x_{1, \\- p} \\\\
          1 & x_{2, \\- 1} & x_{2, \\- 2} & x_{2, \\- 3} & \\cdots & x_{2, \\- p} \\\\
          1 & x_{3, \\- 1} & x_{3, \\- 2} & x_{3, \\- 3} & \\cdots & x_{3, \\- p} \\\\
          1 & x_{4, \\- 1} & x_{4, \\- 2} & x_{4, \\- 3} & \\cdots & x_{4, \\- p} \\\\
          \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\
          1 & x_{n, \\- 1} & x_{n, \\- 2} & x_{n, \\- 3} & \\cdots & x_{n, \\- p} \\\\
          }`});var l=o(y,2);p(l,{children:(v,d)=>{t();var s=R("Также соберём все значения целевой переменной в один вектор");a(v,s)}});var X=o(l,2);r(X,{display:!0,m:"y = (y_1, y_2, y_3, \\dotsc, y_p)^\\T"}),a(f,m)}});var w=o(q,2);b(w,{children:(f,P)=>{var m=O(),i=e(m);p(i,{children:(l,X)=>{t();var v=N(),d=o(e(v));r(d,{m:"a = (a_0, a_1, a_2, \\dotsc, a_p)^\\T"});var s=o(d,2);r(s,{m:"\\epsilon"}),a(l,v)}});var y=o(i,2);r(y,{display:!0,m:"y = X \\cdot a + \\epsilon"}),a(f,m)}});var z=o(w,2);b(z,{children:(f,P)=>{var m=oo(),i=e(m);p(i,{children:($,h)=>{t();var _=Q(),x=o(e(_));r(x,{m:"\\epsilon"}),t(),a($,_)}});var y=o(i,2);r(y,{display:!0,m:"\\RSS(\\epsilon) = \\sum_{j=1}^n \\epsilon_j^2 = \\epsilon^\\T \\cdot \\epsilon"});var l=o(y,2);p(l,{children:($,h)=>{t();var _=U(),x=o(e(_));r(x,{m:"\\epsilon = y - X \\cdot a"}),a($,_)}});var X=o(l,2);p(X,{children:($,h)=>{t();var _=R("Нам нужно, чтобы функция потерь была минимальна, то есть мы решаем задачу оптимизации");a($,_)}});var v=o(X,2);r(v,{display:!0,m:"\\argmin_{a} \\RSS(\\epsilon) = \\argmin_{a}~ (y - X\\cdot a)^\\T \\cdot (y - X \\cdot a)"});var d=o(v,2);p(d,{children:($,h)=>{t();var _=V(),x=o(e(_));r(x,{m:"\\RSS(\\epsilon)"});var g=o(x,2);r(g,{m:"\\epsilon"});var u=o(g,2);r(u,{m:"\\0"}),a($,_)}});var s=o(d,2);r(s,{display:!0,m:"\\nabla \\RSS(\\epsilon) = \\0"});var c=o(s,2);p(c,{children:($,h)=>{t();var _=W(),x=o(e(_));r(x,{m:"\\RSS(\\epsilon)"}),a($,_)}});var T=o(c,2);r(T,{display:!0,m:"(y - X\\cdot a)^\\T \\cdot (y - X \\cdot a) = y^\\T \\cdot y - 2 \\cdot a^\\T \\cdot X^\\T \\cdot y + a^\\T \\cdot X^\\T \\cdot X \\cdot a"});var S=o(T,2);p(S,{children:($,h)=>{t();var _=Y(),x=o(e(_));r(x,{m:"\\nabla \\RSS(\\epsilon) = -2 \\cdot X^\\T \\cdot y + 2 \\cdot X^\\T \\cdot X \\cdot a = \\0"});var g=o(x,2);r(g,{m:"X^\\T \\cdot X \\cdot a = X^\\T \\cdot y"}),t(),a($,_)}});var A=o(S,2);r(A,{display:!0,m:"a = \\bigl( X^\\T \\cdot X \\bigr)^{-1} \\cdot X^T \\cdot y"});var D=o(A,2);p(D,{children:($,h)=>{t();var _=Z(),x=o(e(_));r(x,{m:"\\hess \\RSS(\\epsilon) = 2 \\cdot X^\\T \\cdot X"});var g=o(x,2);r(g,{m:"X^\\T \\cdot X"});var u=o(g,2);r(u,{m:"v"});var E=o(u,2);r(E,{m:"v^\\T \\cdot X^\\T \\cdot X \\cdot v = \\| X \\cdot v \\| \\ge 0"}),t(),a($,_)}}),a(f,m)}});var C=o(z,2);b(C,{children:(f,P)=>{var m=ao(),i=e(m);p(i,{children:(d,s)=>{t();var c=R("Давайте центрируем все признаки.");a(d,c)}});var y=o(i,2);p(y,{children:(d,s)=>{t();var c=ro(),T=o(e(c));r(T,{m:"X^\\T \\cdot X"}),t(),a(d,c)}});var l=o(y,2);r(l,{display:!0,m:`\\frac{1}{n} \\cdot X^\\T \\cdot X = \\pmatrix{
          1 & 0 & 0 & 0 & \\cdots & 0 \\\\
          0 & \\var(x_1) & \\cov(x_1, x_2) & \\cov(x_1, x_3) & \\cdots & \\cov(x_1, x_p) \\\\
          0 & \\cov(x_2, x_1) & \\var(x_2) & \\cov(x_2, x_3) & \\cdots & \\cov(x_2, x_p) \\\\
          0 & \\cov(x_3, x_1) & \\cov(x_3, x_2) & \\var(x_3) & \\cdots & \\cov(x_3, x_p) \\\\
          \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\
          0 & \\cov(x_p, x_1) & \\cov(x_p, x_2) & \\cov(x_p, x_3) & \\cdots & \\var(x_p) \\\\
          }`});var X=o(l,2);p(X,{children:(d,s)=>{t();var c=to(),T=o(e(c));r(T,{m:"X^\\T \\cdot y"}),t(),a(d,c)}});var v=o(X,2);r(v,{display:!0,m:"\\frac{1}{n} \\cdot X^\\T \\cdot y = \\bigl( 0,~ \\cov(y, x_1),~ \\cov(y, x_2),~ \\dotsc,~ \\cov(y, x_p) \\bigr)^\\T"}),a(f,m)}}),a(B,j)}export{go as component};
